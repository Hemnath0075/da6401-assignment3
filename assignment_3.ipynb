{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8a39238",
   "metadata": {},
   "source": [
    "** Question 1 (15 Marks)\n",
    "\n",
    "Build a RNN based seq2seq model which contains the following layers: (i) input layer for character embeddings (ii) one encoder RNN which sequentially encodes the input character sequence (Latin) (iii) one decoder RNN which takes the last state of the encoder as input and produces one output character at a time (Devanagari).\n",
    "\n",
    "The code should be flexible such that the dimension of the input character embeddings, the hidden states of the encoders and decoders, the cell (RNN, LSTM, GRU) and the number of layers in the encoder and decoder can be changed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f33f4e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Automatically use GPU if available\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_vocab_size, embed_size, hidden_size, num_layers=1, cell_type=\"LSTM\"):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_vocab_size, embed_size)\n",
    "        rnn_class = {\"RNN\": nn.RNN, \"LSTM\": nn.LSTM, \"GRU\": nn.GRU}[cell_type]\n",
    "        self.rnn = rnn_class(embed_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.cell_type = cell_type\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "        return hidden\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_vocab_size, embed_size, hidden_size, num_layers=1, cell_type=\"LSTM\"):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_vocab_size, embed_size)\n",
    "        rnn_class = {\"RNN\": nn.RNN, \"LSTM\": nn.LSTM, \"GRU\": nn.GRU}[cell_type]\n",
    "        self.rnn = rnn_class(embed_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_vocab_size)\n",
    "        self.cell_type = cell_type\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        embedded = self.embedding(x)\n",
    "        output, hidden = self.rnn(embedded, hidden)\n",
    "        predictions = self.fc(output.squeeze(1))  # (batch_size, vocab_size)\n",
    "        return predictions, hidden\n",
    "\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, cell_type=\"LSTM\"):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.cell_type = cell_type\n",
    "\n",
    "    def forward(self, source, target, teacher_forcing_ratio=0.5):\n",
    "        batch_size, target_len = target.size()\n",
    "        vocab_size = self.decoder.fc.out_features\n",
    "\n",
    "        outputs = torch.zeros(batch_size, target_len, vocab_size).to(device)\n",
    "        hidden = self.encoder(source)\n",
    "\n",
    "        input = target[:, 0].unsqueeze(1)\n",
    "\n",
    "        for t in range(1, target_len):\n",
    "            output, hidden = self.decoder(input, hidden)\n",
    "            outputs[:, t] = output\n",
    "            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1)\n",
    "            input = target[:, t].unsqueeze(1) if teacher_force else top1.unsqueeze(1)\n",
    "\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c30e415",
   "metadata": {},
   "source": [
    "(a) What is the total number of computations done by your network? (assume that the input embedding size is m, encoder and decoder have 1 layer each, the hidden cell state is kkk for both the encoder and decoder, the length of the input and output sequence is the same, i.e., T, the size of the vocabulary is the same for the source and target language, i.e., V)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc2bb95",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d2dd19c",
   "metadata": {},
   "source": [
    "(b) What is the total number of parameters in your network? (assume that the input embedding size is M, encoder and decoder have 1 layer each, the hidden cell state is k for both the encoder and decoder and the length of the input and output sequence is the same, i.e., T, the size of the vocabulary is the same for the source and target language, i.e., V)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538d9de3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8532c72",
   "metadata": {},
   "source": [
    "Question 2 (10 Marks)\n",
    "You will now train your model using any one language from the Dakshina dataset (I would suggest pick a language that you can read so that it is easy to analyse the errors). Use the standard train, dev, test set from the folder dakshina_dataset_v1.0/hi/lexicons/ (replace hi by the language of your choice)\n",
    "\n",
    "Using the sweep feature in wandb find the best hyperparameter configuration. Here are some suggestions but you are free to decide which hyperparameters you want to explore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd516c7",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
