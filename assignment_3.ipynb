{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8a39238",
   "metadata": {},
   "source": [
    "## Question 1 (15 Marks)\n",
    "\n",
    "Build a RNN based seq2seq model which contains the following layers: (i) input layer for character embeddings (ii) one encoder RNN which sequentially encodes the input character sequence (Latin) (iii) one decoder RNN which takes the last state of the encoder as input and produces one output character at a time (Devanagari).\n",
    "\n",
    "The code should be flexible such that the dimension of the input character embeddings, the hidden states of the encoders and decoders, the cell (RNN, LSTM, GRU) and the number of layers in the encoder and decoder can be changed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f33f4e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/e_disk/ch24s016/da6401_assignment3/.venv/lib/python3.10/site-packages/torch/_subclasses/functional_tensor.py:276: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:81.)\n",
      "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_vocab_size, embed_size, hidden_size, num_layers=1, cell_type=\"LSTM\"):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_vocab_size, embed_size)\n",
    "        rnn_class = {\"RNN\": nn.RNN, \"LSTM\": nn.LSTM, \"GRU\": nn.GRU}[cell_type]\n",
    "        self.rnn = rnn_class(embed_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.cell_type = cell_type\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "        return hidden\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_vocab_size, embed_size, hidden_size, num_layers=1, cell_type=\"LSTM\"):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_vocab_size, embed_size)\n",
    "        rnn_class = {\"RNN\": nn.RNN, \"LSTM\": nn.LSTM, \"GRU\": nn.GRU}[cell_type]\n",
    "        self.rnn = rnn_class(embed_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_vocab_size)\n",
    "        self.cell_type = cell_type\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        embedded = self.embedding(x)\n",
    "        output, hidden = self.rnn(embedded, hidden)\n",
    "        predictions = self.fc(output.squeeze(1))  # (batch_size, vocab_size)\n",
    "        return predictions, hidden\n",
    "\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, cell_type=\"LSTM\"):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.cell_type = cell_type\n",
    "\n",
    "    def forward(self, source, target, teacher_forcing_ratio=0.5):\n",
    "        batch_size, target_len = target.size()\n",
    "        vocab_size = self.decoder.fc.out_features\n",
    "\n",
    "        outputs = torch.zeros(batch_size, target_len, vocab_size).to(device)\n",
    "        hidden = self.encoder(source)\n",
    "\n",
    "        input = target[:, 0].unsqueeze(1)\n",
    "\n",
    "        for t in range(1, target_len):\n",
    "            output, hidden = self.decoder(input, hidden)\n",
    "            outputs[:, t] = output\n",
    "            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1)\n",
    "            input = target[:, t].unsqueeze(1) if teacher_force else top1.unsqueeze(1)\n",
    "\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c30e415",
   "metadata": {},
   "source": [
    "(a) What is the total number of computations done by your network? (assume that the input embedding size is m, encoder and decoder have 1 layer each, the hidden cell state is kkk for both the encoder and decoder, the length of the input and output sequence is the same, i.e., T, the size of the vocabulary is the same for the source and target language, i.e., V)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc2bb95",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d2dd19c",
   "metadata": {},
   "source": [
    "(b) What is the total number of parameters in your network? (assume that the input embedding size is M, encoder and decoder have 1 layer each, the hidden cell state is k for both the encoder and decoder and the length of the input and output sequence is the same, i.e., T, the size of the vocabulary is the same for the source and target language, i.e., V)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538d9de3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8532c72",
   "metadata": {},
   "source": [
    "## Question 2 (10 Marks)\n",
    "You will now train your model using any one language from the Dakshina dataset (I would suggest pick a language that you can read so that it is easy to analyse the errors). Use the standard train, dev, test set from the folder dakshina_dataset_v1.0/hi/lexicons/ (replace hi by the language of your choice)\n",
    "\n",
    "Using the sweep feature in wandb find the best hyperparameter configuration. Here are some suggestions but you are free to decide which hyperparameters you want to explore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fd08831",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(filepaths):\n",
    "    chars = set()\n",
    "    for filepath in filepaths:\n",
    "        with open(filepath, encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                native, roman, _ = line.strip().split(\"\\t\")\n",
    "                chars.update(native)\n",
    "                chars.update(roman)\n",
    "    return chars\n",
    "\n",
    "def make_char2idx(char_set):\n",
    "    char_list = [\"<pad>\", \"<sos>\", \"<eos>\", \"<unk>\"] + sorted(list(char_set))\n",
    "    return {char: idx for idx, char in enumerate(char_list)}, char_list\n",
    "\n",
    "train_path = \"/mnt/e_disk/ch24s016/da6401_assignment3/dataset/dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.train.tsv\"\n",
    "dev_path = \"/mnt/e_disk/ch24s016/da6401_assignment3/dataset/dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.dev.tsv\"\n",
    "\n",
    "char_set = build_vocab([train_path, dev_path])\n",
    "roman2idx, idx2roman = make_char2idx(set(c for c in char_set if c.isascii()))\n",
    "devanagari2idx, idx2devanagari = make_char2idx(set(c for c in char_set if not c.isascii()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2844381",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_batch(batch):\n",
    "    src_batch, tgt_batch = zip(*batch)\n",
    "    src_batch = pad_sequence(src_batch, padding_value=roman2idx[\"<pad>\"], batch_first=True)\n",
    "    tgt_batch = pad_sequence(tgt_batch, padding_value=devanagari2idx[\"<pad>\"], batch_first=True)\n",
    "    return src_batch, tgt_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cf0e5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TransliterationDataset(Dataset):\n",
    "    def __init__(self, tsv_path, src_char2idx, tgt_char2idx, max_len=32):\n",
    "        self.pairs = []\n",
    "        with open(tsv_path, encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                native, roman, _ = line.strip().split('\\t')\n",
    "                self.pairs.append((roman, native))\n",
    "\n",
    "        self.src_c2i = src_char2idx\n",
    "        self.tgt_c2i = tgt_char2idx\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        roman, native = self.pairs[i]\n",
    "\n",
    "        # map chars → indices, add <sos> / <eos> tokens as needed\n",
    "        src_idxs = [self.src_c2i.get(c, self.src_c2i[\"<unk>\"]) \n",
    "                    for c in roman][: self.max_len]\n",
    "        tgt_idxs = [self.tgt_c2i[\"<sos>\"]] + \\\n",
    "                   [self.tgt_c2i.get(c, self.tgt_c2i[\"<unk>\"]) \n",
    "                    for c in native][: (self.max_len-1)] + \\\n",
    "                   [self.tgt_c2i[\"<eos>\"]]\n",
    "\n",
    "        return torch.tensor(src_idxs), torch.tensor(tgt_idxs)\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    src_seqs, tgt_seqs = zip(*batch)\n",
    "\n",
    "    src_max_len = max(seq.size(0) for seq in src_seqs)\n",
    "    tgt_max_len = max(seq.size(0) for seq in tgt_seqs)\n",
    "\n",
    "\n",
    "    src_padded = torch.stack([\n",
    "        torch.cat([seq, torch.full((src_max_len - len(seq),), roman2idx[\"<pad>\"], dtype=torch.long)])\n",
    "        for seq in src_seqs\n",
    "    ])\n",
    "\n",
    "    tgt_padded = torch.stack([\n",
    "        torch.cat([seq, torch.full((tgt_max_len - len(seq),), devanagari2idx[\"<pad>\"], dtype=torch.long)])\n",
    "        for seq in tgt_seqs\n",
    "    ])\n",
    "\n",
    "    return src_padded, tgt_padded\n",
    "\n",
    "train_ds = TransliterationDataset(\n",
    "    \"/mnt/e_disk/ch24s016/da6401_assignment3/dataset/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.train.tsv\",\n",
    "    src_char2idx=roman2idx,\n",
    "    tgt_char2idx=devanagari2idx,\n",
    "    max_len=32\n",
    ")\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "train_dataset = TransliterationDataset(train_path, roman2idx, devanagari2idx, max_len=32)\n",
    "dev_dataset = TransliterationDataset(dev_path, roman2idx, devanagari2idx, max_len=32)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_batch)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=32, shuffle=False, collate_fn=collate_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "421154af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 3734.5742, Train Acc: 0.6121, Val Acc: 0.5876\n",
      "Epoch 2/10, Loss: 1666.9953, Train Acc: 0.7547, Val Acc: 0.7093\n",
      "Epoch 3/10, Loss: 1224.1711, Train Acc: 0.8027, Val Acc: 0.7403\n",
      "Epoch 4/10, Loss: 1031.5823, Train Acc: 0.8336, Val Acc: 0.7648\n",
      "Epoch 5/10, Loss: 900.4773, Train Acc: 0.8582, Val Acc: 0.7813\n",
      "Epoch 6/10, Loss: 821.7708, Train Acc: 0.8678, Val Acc: 0.7822\n",
      "Epoch 7/10, Loss: 747.3668, Train Acc: 0.8779, Val Acc: 0.7852\n",
      "Epoch 8/10, Loss: 694.8574, Train Acc: 0.8881, Val Acc: 0.7858\n",
      "Epoch 9/10, Loss: 650.6924, Train Acc: 0.8960, Val Acc: 0.7929\n",
      "Epoch 10/10, Loss: 619.3768, Train Acc: 0.9005, Val Acc: 0.7892\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Hyperparameters\n",
    "\n",
    "embed_size = 64\n",
    "hidden_size = 128\n",
    "num_layers = 1\n",
    "cell_type = \"LSTM\"\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "lr = 0.001\n",
    "\n",
    "# Initialize model\n",
    "encoder = Encoder(len(roman2idx), embed_size, hidden_size, num_layers, cell_type).to(device)\n",
    "decoder = Decoder(len(devanagari2idx), embed_size, hidden_size, num_layers, cell_type).to(device)\n",
    "model = Seq2Seq(encoder, decoder, cell_type).to(device)\n",
    "\n",
    "# Optimizer and loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "loss_function = nn.CrossEntropyLoss(ignore_index=devanagari2idx[\"<pad>\"])\n",
    "\n",
    "def evaluate_accuracy(model, dataloader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for src, tgt in dataloader:\n",
    "            src, tgt = src.to(device), tgt.to(device)\n",
    "            output = model(src, tgt, teacher_forcing_ratio=0.0)\n",
    "            pred = output.argmax(dim=2)\n",
    "            for i in range(tgt.size(0)):\n",
    "                for j in range(1, tgt.size(1)):\n",
    "                    if tgt[i, j].item() == devanagari2idx[\"<pad>\"]:\n",
    "                        break\n",
    "                    if pred[i, j].item() == tgt[i, j].item():\n",
    "                        correct += 1\n",
    "                    total += 1\n",
    "    return correct / total if total > 0 else 0.0\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for src, tgt in train_loader:\n",
    "        src, tgt = src.to(device), tgt.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, tgt)\n",
    "        output = output[:, 1:].reshape(-1, output.shape[-1])\n",
    "        tgt_flat = tgt[:, 1:].reshape(-1)\n",
    "        loss = loss_function(output, tgt_flat)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    train_acc = evaluate_accuracy(model, train_loader)\n",
    "    dev_acc = evaluate_accuracy(model, dev_loader)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {dev_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c85abdf",
   "metadata": {},
   "source": [
    "## Wandb Sweep Run to Find Best Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b1d5148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: gy0rcmqo\n",
      "Sweep URL: https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/sweeps/gy0rcmqo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: tidwg9cp with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: RNN\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mch24s016\u001b[0m (\u001b[33mch24s016-iitm\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/e_disk/ch24s016/da6401_assignment3/wandb/run-20250520_001751-tidwg9cp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/runs/tidwg9cp' target=\"_blank\">whole-sweep-1</a></strong> to <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/sweeps/gy0rcmqo' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/sweeps/gy0rcmqo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/sweeps/gy0rcmqo' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/sweeps/gy0rcmqo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/runs/tidwg9cp' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/runs/tidwg9cp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 5304.8279, Train Acc: 0.1832, Val Acc: 0.1831\n",
      "Epoch 2/10, Loss: 5081.6520, Train Acc: 0.1621, Val Acc: 0.1320\n",
      "Epoch 3/10, Loss: 4954.2290, Train Acc: 0.1751, Val Acc: 0.1641\n",
      "Epoch 4/10, Loss: 4881.5742, Train Acc: 0.1910, Val Acc: 0.1687\n",
      "Epoch 5/10, Loss: 4850.3568, Train Acc: 0.1862, Val Acc: 0.1599\n",
      "Epoch 6/10, Loss: 4842.0607, Train Acc: 0.1910, Val Acc: 0.1791\n",
      "Epoch 7/10, Loss: 4775.6646, Train Acc: 0.1962, Val Acc: 0.1757\n",
      "Epoch 8/10, Loss: 4798.3265, Train Acc: 0.1768, Val Acc: 0.1628\n",
      "Epoch 9/10, Loss: 4798.1818, Train Acc: 0.1846, Val Acc: 0.1805\n",
      "Epoch 10/10, Loss: 4817.1717, Train Acc: 0.1957, Val Acc: 0.1781\n",
      "Model saved to ./trained_models/model_whole-sweep-1.pt\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>loss</td><td>█▅▃▂▂▂▁▁▁▂</td></tr><tr><td>train_accuracy</td><td>▅▁▄▇▆▇█▄▆█</td></tr><tr><td>val_accuracy</td><td>█▁▅▆▅▇▇▅█▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>loss</td><td>4817.17166</td></tr><tr><td>train_accuracy</td><td>0.19567</td></tr><tr><td>val_accuracy</td><td>0.17806</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">whole-sweep-1</strong> at: <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/runs/tidwg9cp' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/runs/tidwg9cp</a><br> View project at: <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250520_001751-tidwg9cp/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wod6ukdz with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/e_disk/ch24s016/da6401_assignment3/wandb/run-20250520_003113-wod6ukdz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/runs/wod6ukdz' target=\"_blank\">electric-sweep-2</a></strong> to <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/sweeps/gy0rcmqo' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/sweeps/gy0rcmqo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/sweeps/gy0rcmqo' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/sweeps/gy0rcmqo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/runs/wod6ukdz' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/runs/wod6ukdz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 2627.3083, Train Acc: 0.6320, Val Acc: 0.6144\n",
      "Epoch 2/5, Loss: 1800.1574, Train Acc: 0.6844, Val Acc: 0.6539\n",
      "Epoch 3/5, Loss: 1617.1992, Train Acc: 0.7126, Val Acc: 0.6816\n",
      "Epoch 4/5, Loss: 1507.5024, Train Acc: 0.7283, Val Acc: 0.6831\n",
      "Epoch 5/5, Loss: 1446.1775, Train Acc: 0.7350, Val Acc: 0.6927\n",
      "Model saved to ./trained_models/model_electric-sweep-2.pt\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>loss</td><td>█▃▂▁▁</td></tr><tr><td>train_accuracy</td><td>▁▅▆██</td></tr><tr><td>val_accuracy</td><td>▁▅▇▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>loss</td><td>1446.17755</td></tr><tr><td>train_accuracy</td><td>0.73504</td></tr><tr><td>val_accuracy</td><td>0.69271</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">electric-sweep-2</strong> at: <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/runs/wod6ukdz' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/runs/wod6ukdz</a><br> View project at: <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250520_003113-wod6ukdz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: skauucbb with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/e_disk/ch24s016/da6401_assignment3/wandb/run-20250520_003832-skauucbb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/runs/skauucbb' target=\"_blank\">proud-sweep-3</a></strong> to <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/sweeps/gy0rcmqo' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/sweeps/gy0rcmqo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/sweeps/gy0rcmqo' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/sweeps/gy0rcmqo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/runs/skauucbb' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/runs/skauucbb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">proud-sweep-3</strong> at: <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/runs/skauucbb' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/runs/skauucbb</a><br> View project at: <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250520_003832-skauucbb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run skauucbb errored:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/mnt/e_disk/ch24s016/da6401_assignment3/.venv/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_3752887/2263630927.py\", line 70, in train_sweep\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise ValueError(\"Unsupported optimizer\")\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m ValueError: Unsupported optimizer\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 17b57hme with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/e_disk/ch24s016/da6401_assignment3/wandb/run-20250520_003837-17b57hme</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/runs/17b57hme' target=\"_blank\">swept-sweep-4</a></strong> to <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/sweeps/gy0rcmqo' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/sweeps/gy0rcmqo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/sweeps/gy0rcmqo' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/sweeps/gy0rcmqo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/runs/17b57hme' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/runs/17b57hme</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">swept-sweep-4</strong> at: <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/runs/17b57hme' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/runs/17b57hme</a><br> View project at: <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250520_003837-17b57hme/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 17b57hme errored:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/mnt/e_disk/ch24s016/da6401_assignment3/.venv/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_3752887/2263630927.py\", line 70, in train_sweep\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise ValueError(\"Unsupported optimizer\")\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m ValueError: Unsupported optimizer\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qdmwzeam with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/e_disk/ch24s016/da6401_assignment3/wandb/run-20250520_003842-qdmwzeam</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/runs/qdmwzeam' target=\"_blank\">rosy-sweep-5</a></strong> to <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/sweeps/gy0rcmqo' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/sweeps/gy0rcmqo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/sweeps/gy0rcmqo' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/sweeps/gy0rcmqo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/runs/qdmwzeam' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/runs/qdmwzeam</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">rosy-sweep-5</strong> at: <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/runs/qdmwzeam' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/runs/qdmwzeam</a><br> View project at: <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250520_003842-qdmwzeam/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run qdmwzeam errored:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/mnt/e_disk/ch24s016/da6401_assignment3/.venv/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_3752887/2263630927.py\", line 70, in train_sweep\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise ValueError(\"Unsupported optimizer\")\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m ValueError: Unsupported optimizer\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: znri238s with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/e_disk/ch24s016/da6401_assignment3/wandb/run-20250520_003849-znri238s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/runs/znri238s' target=\"_blank\">trim-sweep-6</a></strong> to <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/sweeps/gy0rcmqo' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/sweeps/gy0rcmqo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/sweeps/gy0rcmqo' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/sweeps/gy0rcmqo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/runs/znri238s' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/runs/znri238s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 4549.6156, Train Acc: 0.3918, Val Acc: 0.3865\n",
      "Epoch 2/5, Loss: 2932.7173, Train Acc: 0.5204, Val Acc: 0.4976\n",
      "Epoch 3/5, Loss: 2372.2580, Train Acc: 0.5759, Val Acc: 0.5430\n",
      "Epoch 4/5, Loss: 2098.8817, Train Acc: 0.6185, Val Acc: 0.5858\n",
      "Epoch 5/5, Loss: 1942.2648, Train Acc: 0.6489, Val Acc: 0.6099\n",
      "Model saved to ./trained_models/model_trim-sweep-6.pt\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>loss</td><td>█▄▂▁▁</td></tr><tr><td>train_accuracy</td><td>▁▅▆▇█</td></tr><tr><td>val_accuracy</td><td>▁▄▆▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>loss</td><td>1942.26477</td></tr><tr><td>train_accuracy</td><td>0.6489</td></tr><tr><td>val_accuracy</td><td>0.60989</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trim-sweep-6</strong> at: <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/runs/znri238s' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/runs/znri238s</a><br> View project at: <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250520_003849-znri238s/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: frkzwuqy with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/e_disk/ch24s016/da6401_assignment3/wandb/run-20250520_004602-frkzwuqy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/runs/frkzwuqy' target=\"_blank\">honest-sweep-7</a></strong> to <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/sweeps/gy0rcmqo' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/sweeps/gy0rcmqo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/sweeps/gy0rcmqo' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/sweeps/gy0rcmqo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/runs/frkzwuqy' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/runs/frkzwuqy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 4840.6998, Train Acc: 0.3477, Val Acc: 0.3419\n",
      "Epoch 2/10, Loss: 2782.0607, Train Acc: 0.5811, Val Acc: 0.5608\n",
      "Epoch 3/10, Loss: 1866.0788, Train Acc: 0.7014, Val Acc: 0.6629\n",
      "Epoch 4/10, Loss: 1473.4992, Train Acc: 0.7572, Val Acc: 0.7071\n",
      "Epoch 5/10, Loss: 1254.7539, Train Acc: 0.7937, Val Acc: 0.7345\n",
      "Epoch 6/10, Loss: 1112.7068, Train Acc: 0.8143, Val Acc: 0.7457\n",
      "Epoch 7/10, Loss: 1008.2076, Train Acc: 0.8362, Val Acc: 0.7728\n",
      "Epoch 8/10, Loss: 927.8417, Train Acc: 0.8413, Val Acc: 0.7703\n",
      "Epoch 9/10, Loss: 863.1061, Train Acc: 0.8548, Val Acc: 0.7767\n",
      "Epoch 10/10, Loss: 808.9390, Train Acc: 0.8648, Val Acc: 0.7816\n",
      "Model saved to ./trained_models/model_honest-sweep-7.pt\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>loss</td><td>█▄▃▂▂▂▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▄▆▇▇▇████</td></tr><tr><td>val_accuracy</td><td>▁▄▆▇▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>loss</td><td>808.93899</td></tr><tr><td>train_accuracy</td><td>0.86479</td></tr><tr><td>val_accuracy</td><td>0.78159</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">honest-sweep-7</strong> at: <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/runs/frkzwuqy' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/runs/frkzwuqy</a><br> View project at: <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250520_004602-frkzwuqy/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: w59gx9zd with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: RNN\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/e_disk/ch24s016/da6401_assignment3/wandb/run-20250520_010052-w59gx9zd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/runs/w59gx9zd' target=\"_blank\">morning-sweep-8</a></strong> to <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/sweeps/gy0rcmqo' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/sweeps/gy0rcmqo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/sweeps/gy0rcmqo' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/sweeps/gy0rcmqo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/runs/w59gx9zd' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/runs/w59gx9zd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 5410.3484, Train Acc: 0.1564, Val Acc: 0.1530\n",
      "Epoch 2/10, Loss: 5184.6143, Train Acc: 0.1466, Val Acc: 0.1511\n",
      "Epoch 3/10, Loss: 5131.9613, Train Acc: 0.1744, Val Acc: 0.1712\n",
      "Epoch 4/10, Loss: 5031.5812, Train Acc: 0.1813, Val Acc: 0.1736\n",
      "Epoch 5/10, Loss: 4985.3394, Train Acc: 0.1797, Val Acc: 0.1696\n",
      "Epoch 6/10, Loss: 4967.6654, Train Acc: 0.1864, Val Acc: 0.1794\n",
      "Epoch 7/10, Loss: 4948.1991, Train Acc: 0.1911, Val Acc: 0.1805\n",
      "Epoch 8/10, Loss: 4907.8394, Train Acc: 0.1985, Val Acc: 0.1925\n",
      "Epoch 9/10, Loss: 4878.5995, Train Acc: 0.1798, Val Acc: 0.1734\n",
      "Epoch 10/10, Loss: 4887.3298, Train Acc: 0.1682, Val Acc: 0.1627\n",
      "Model saved to ./trained_models/model_morning-sweep-8.pt\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>loss</td><td>█▅▄▃▂▂▂▁▁▁</td></tr><tr><td>train_accuracy</td><td>▂▁▅▆▅▆▇█▅▄</td></tr><tr><td>val_accuracy</td><td>▁▁▄▅▄▆▆█▅▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>loss</td><td>4887.32977</td></tr><tr><td>train_accuracy</td><td>0.16822</td></tr><tr><td>val_accuracy</td><td>0.16272</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">morning-sweep-8</strong> at: <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/runs/w59gx9zd' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/runs/w59gx9zd</a><br> View project at: <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250520_010052-w59gx9zd/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2ywg20ia with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/e_disk/ch24s016/da6401_assignment3/wandb/run-20250520_011425-2ywg20ia</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/runs/2ywg20ia' target=\"_blank\">revived-sweep-9</a></strong> to <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/sweeps/gy0rcmqo' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/sweeps/gy0rcmqo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/sweeps/gy0rcmqo' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/sweeps/gy0rcmqo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/runs/2ywg20ia' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/runs/2ywg20ia</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 4292.6543, Train Acc: 0.4355, Val Acc: 0.4256\n",
      "Epoch 2/5, Loss: 2276.1394, Train Acc: 0.6457, Val Acc: 0.6132\n",
      "Epoch 3/5, Loss: 1620.9036, Train Acc: 0.7297, Val Acc: 0.6838\n",
      "Epoch 4/5, Loss: 1323.9823, Train Acc: 0.7811, Val Acc: 0.7250\n",
      "Epoch 5/5, Loss: 1148.9194, Train Acc: 0.8047, Val Acc: 0.7406\n",
      "Model saved to ./trained_models/model_revived-sweep-9.pt\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>loss</td><td>█▄▂▁▁</td></tr><tr><td>train_accuracy</td><td>▁▅▇██</td></tr><tr><td>val_accuracy</td><td>▁▅▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>loss</td><td>1148.9194</td></tr><tr><td>train_accuracy</td><td>0.80475</td></tr><tr><td>val_accuracy</td><td>0.74059</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">revived-sweep-9</strong> at: <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/runs/2ywg20ia' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/runs/2ywg20ia</a><br> View project at: <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250520_011425-2ywg20ia/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3bs7bqxn with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/e_disk/ch24s016/da6401_assignment3/wandb/run-20250520_012200-3bs7bqxn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/runs/3bs7bqxn' target=\"_blank\">major-sweep-10</a></strong> to <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/sweeps/gy0rcmqo' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/sweeps/gy0rcmqo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/sweeps/gy0rcmqo' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/sweeps/gy0rcmqo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/runs/3bs7bqxn' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/runs/3bs7bqxn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">major-sweep-10</strong> at: <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/runs/3bs7bqxn' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/runs/3bs7bqxn</a><br> View project at: <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250520_012200-3bs7bqxn/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 3bs7bqxn errored:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/mnt/e_disk/ch24s016/da6401_assignment3/.venv/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_3752887/2263630927.py\", line 70, in train_sweep\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise ValueError(\"Unsupported optimizer\")\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m ValueError: Unsupported optimizer\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import os\n",
    "\n",
    "sweep_config = {\n",
    "    'method': 'bayes',\n",
    "    'name': 'Seq2Seq Transliteration Sweep',\n",
    "    'metric': {'name': \"val_accuracy\", 'goal': 'maximize'},\n",
    "    'parameters': {\n",
    "        'embed_size': {'values': [32, 64, 128]},\n",
    "        'hidden_size': {'values': [64, 128, 256]},\n",
    "        'num_layers': {'values': [1]},\n",
    "        'cell_type': {'values': ['RNN', 'GRU', 'LSTM']},\n",
    "        'optimizer': {'values': ['adam', 'adamw', 'sgd']},\n",
    "        'lr': {'values': [0.01, 0.001, 0.0005]},\n",
    "        'batch_size': {'values': [16, 32, 64]},\n",
    "        'epochs': {'values': [5, 10]}\n",
    "    },\n",
    "}\n",
    "\n",
    "def evaluate_accuracy(model, dataloader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for src, tgt in dataloader:\n",
    "            src, tgt = src.to(device), tgt.to(device)\n",
    "            output = model(src, tgt, teacher_forcing_ratio=0.0)\n",
    "            pred = output.argmax(dim=2)\n",
    "            for i in range(tgt.size(0)):\n",
    "                for j in range(1, tgt.size(1)):\n",
    "                    if tgt[i, j].item() == devanagari2idx[\"<pad>\"]:\n",
    "                        break\n",
    "                    if pred[i, j].item() == tgt[i, j].item():\n",
    "                        correct += 1\n",
    "                    total += 1\n",
    "    return correct / total if total > 0 else 0.0\n",
    "\n",
    "def train_sweep():\n",
    "    wandb.init()\n",
    "    config = wandb.config\n",
    "\n",
    "    # Update hyperparameters from sweep config\n",
    "    embed_size = config.embed_size\n",
    "    hidden_size = config.hidden_size\n",
    "    num_layers = config.num_layers\n",
    "    cell_type = config.cell_type\n",
    "    batch_size = config.batch_size\n",
    "    epochs = config.epochs\n",
    "    lr = config.lr\n",
    "\n",
    "    # Update data loader if batch_size changes\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "    dev_loader = DataLoader(dev_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "    # Model setup\n",
    "    encoder = Encoder(len(roman2idx), embed_size, hidden_size, num_layers, cell_type).to(device)\n",
    "    decoder = Decoder(len(devanagari2idx), embed_size, hidden_size, num_layers, cell_type).to(device)\n",
    "    model = Seq2Seq(encoder, decoder, cell_type).to(device)\n",
    "\n",
    "    # Optimizer\n",
    "    if config.optimizer == 'adam':\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    elif config.optimizer == 'adamw':\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    # \n",
    "    # elif config.optimizer == 'sgd':\n",
    "    #     optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    # elif config.optimizer == 'rmsprop':\n",
    "    #     optimizer = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported optimizer\")\n",
    "\n",
    "    # Loss function\n",
    "    loss_function = nn.CrossEntropyLoss(ignore_index=devanagari2idx[\"<pad>\"])\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for src, tgt in train_loader:\n",
    "            src, tgt = src.to(device), tgt.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(src, tgt)\n",
    "            output = output[:, 1:].reshape(-1, output.shape[-1])\n",
    "            tgt_flat = tgt[:, 1:].reshape(-1)\n",
    "            loss = loss_function(output, tgt_flat)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        train_acc = evaluate_accuracy(model, train_loader)\n",
    "        val_acc = evaluate_accuracy(model, dev_loader)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"loss\": total_loss,\n",
    "            \"train_accuracy\": train_acc,\n",
    "            \"val_accuracy\": val_acc\n",
    "        })\n",
    "        \n",
    "    model_dir = \"./trained_models\"\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    # Unique file name using wandb run name or ID\n",
    "    run_id = wandb.run.name  # or wandb.run.id\n",
    "    model_path = os.path.join(model_dir, f\"model_{run_id}.pt\")\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    print(f\"Model saved to {model_path}\")\n",
    "\n",
    "    wandb.finish()\n",
    "    \n",
    "sweep_id = wandb.sweep(sweep_config, project=\"Seq2SeqAssignment3\")\n",
    "wandb.agent(sweep_id, function=train_sweep, count=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd516c7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5cc0e88e",
   "metadata": {},
   "source": [
    "Question 4 (10 Marks)\n",
    "You will now apply your best model on the test data (You shouldn't have used test data so far. All the above experiments should have been done using train and val data only).\n",
    "\n",
    "(a) Use the best model from your sweep and report the accuracy on the test set (the output is correct only if it exactly matches the reference output).\n",
    "\n",
    "(b) Provide sample inputs from the test data and predictions made by your best model (more marks for presenting this grid creatively). Also upload all the predictions on the test set in a folder predictions_vanilla on your github project.\n",
    "\n",
    "(c) Comment on the errors made by your model (simple insightful bullet points)\n",
    "\n",
    "The model makes more errors on consonants than vowels\n",
    "The model makes more errors on longer sequences\n",
    "I am thinking confusion matrix but may be it's just me!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3852dc59",
   "metadata": {},
   "source": [
    "### the best model parameters that we got so far is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75b03975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'Seq2SeqAssignment3' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Ignoring entity 'ch24s016-iitm' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">bestsweepsofar</strong> at: <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/runs/3bs7bqxn' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/runs/3bs7bqxn</a><br> View project at: <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250520_013230-3bs7bqxn/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/e_disk/ch24s016/da6401_assignment3/wandb/run-20250520_020048-3bs7bqxn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/runs/3bs7bqxn' target=\"_blank\">bestsweepsofar</a></strong> to <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/sweeps/gy0rcmqo' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/sweeps/gy0rcmqo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/sweeps/gy0rcmqo' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/sweeps/gy0rcmqo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/runs/3bs7bqxn' target=\"_blank\">https://wandb.ai/ch24s016-iitm/Seq2SeqAssignment3/runs/3bs7bqxn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Run ch24s016-iitm/Seq2SeqAssignment3/frkzwuqy (finished)>\n",
      "{'lr': 0.0005, 'epochs': 10, 'cell_type': 'LSTM', 'optimizer': 'adamw', 'batch_size': 32, 'embed_size': 32, 'num_layers': 1, 'hidden_size': 128}\n"
     ]
    }
   ],
   "source": [
    "wandb.init(project=\"Seq2SeqAssignment3\",entity=\"ch24s016-iitm\",name='bestsweepsofar')\n",
    "api = wandb.Api()\n",
    "\n",
    "# Fetch all runs in the sweep\n",
    "sweep_runs = api.sweep(f\"ch24s016-iitm/Seq2SeqAssignment3/gy0rcmqo/\").runs\n",
    "\n",
    "\n",
    "# Find the best model based on validation accuracy\n",
    "best_run = max(sweep_runs, key=lambda run: run.summary.get(\"val_accuracy\", 0))\n",
    "print(best_run)\n",
    "print(best_run.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f84797",
   "metadata": {},
   "source": [
    "we are going to use this model and generate the test outputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "19905332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions written to prediction_attention.tsv\n"
     ]
    }
   ],
   "source": [
    "train_path = \"/mnt/e_disk/ch24s016/da6401_assignment3/dataset/dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.train.tsv\"\n",
    "dev_path = \"/mnt/e_disk/ch24s016/da6401_assignment3/dataset/dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.dev.tsv\"\n",
    "\n",
    "char_set = build_vocab([train_path, dev_path])\n",
    "roman2idx, idx2roman = make_char2idx(set(c for c in char_set if c.isascii()))\n",
    "devanagari2idx, idx2devanagari = make_char2idx(set(c for c in char_set if not c.isascii()))\n",
    "\n",
    "\n",
    "test_path = \"/mnt/e_disk/ch24s016/da6401_assignment3/dataset/dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.test.tsv\"\n",
    "\n",
    "test_dataset = TransliterationDataset(test_path, roman2idx, devanagari2idx, max_len=32)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, collate_fn=collate_batch)\n",
    "\n",
    "\n",
    "checkpoint = torch.load(\"/mnt/e_disk/ch24s016/da6401_assignment3/trained_models/model_honest-sweep-7.pt\", map_location=device)\n",
    "\n",
    "# print(checkpoint)?\n",
    "embed_size = 32\n",
    "hidden_size = 128\n",
    "num_layers = 1\n",
    "cell_type = 'LSTM'\n",
    "\n",
    "src_vocab_size = len(roman2idx)\n",
    "tgt_vocab_size = len(devanagari2idx)\n",
    "\n",
    "encoder = Encoder(src_vocab_size, embed_size, hidden_size, num_layers, cell_type).to(device)\n",
    "decoder = Decoder(tgt_vocab_size, embed_size, hidden_size, num_layers, cell_type).to(device)\n",
    "model = Seq2Seq(encoder, decoder, cell_type).to(device)\n",
    "\n",
    "# Load state dict directly from checkpoint dict\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()\n",
    "\n",
    "def predict(model, input_str, roman2idx, idx2devanagari, max_len=32):\n",
    "    model.eval()\n",
    "\n",
    "    # Convert input string to index tensor\n",
    "    input_idxs = [roman2idx.get(c, roman2idx[\"<unk>\"]) for c in input_str]\n",
    "    input_tensor = torch.tensor(input_idxs, dtype=torch.long).unsqueeze(0).to(device)  # (1, seq_len)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        hidden = model.encoder(input_tensor)\n",
    "\n",
    "        # Start with <sos>\n",
    "        input_dec = torch.tensor([[devanagari2idx[\"<sos>\"]]], dtype=torch.long).to(device)\n",
    "\n",
    "        output_tokens = []\n",
    "        for _ in range(max_len):\n",
    "            output, hidden = model.decoder(input_dec, hidden)\n",
    "            top1 = output.argmax(1).item()\n",
    "\n",
    "            if top1 == devanagari2idx[\"<eos>\"]:\n",
    "                break\n",
    "\n",
    "            output_tokens.append(top1)\n",
    "            input_dec = torch.tensor([[top1]], dtype=torch.long).to(device)\n",
    "\n",
    "    # Convert indices back to characters\n",
    "    return ''.join([idx2devanagari[i] for i in output_tokens])\n",
    "\n",
    "# --- Transliterate test set and write predictions ---\n",
    "output_file = \"prediction_attention.tsv\"\n",
    "with open(test_path, 'r', encoding='utf-8') as f_in, open(output_file, 'w', encoding='utf-8') as f_out:\n",
    "    for line in f_in:\n",
    "        parts = line.strip().split('\\t')\n",
    "        if len(parts) < 2:\n",
    "            continue\n",
    "        roman = parts[1]\n",
    "        src_idxs = [roman2idx.get(c, roman2idx[\"<unk>\"]) for c in roman]\n",
    "        pred = predict(model, roman, roman2idx, idx2devanagari)\n",
    "        f_out.write(f\"{roman}\\t{pred}\\n\")\n",
    "\n",
    "print(f\"Predictions written to {output_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f131b148",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
